{"name":"rspec-llama","downloads":226,"version":"0.1.0","version_created_at":"2024-10-02T21:58:56.381Z","version_downloads":226,"platform":"ruby","authors":"Vadim S., Artur A., Anatoli L., Sergy S.","info":"RSpec::Llama is a testing framework that allows developers to easily configure, run, and validate\nAI models such as OpenAI's GPT models, Llama, and others within the RSpec ecosystem.\n\nWith a focus on simplicity and extensibility, RSpec::Llama provides:\n- A standardized approach to configuring different AI models with customizable parameters.\n- Runners to execute model interactions and capture responses seamlessly.\n- Comprehensive assertion types to validate model outputs against expected patterns.\n\nWhether you are developing AI-powered applications or simply need a reliable way to test various AI\nmodels' outputs, RSpec::Llama offers an all-in-one solution that integrates smoothly into your existing RSpec setup.\n","licenses":["Apache-2.0"],"metadata":{"rubygems_mfa_required":"true"},"yanked":false,"sha":"fb29154ab1c9770abc0d97c26a1fd041890eaae9979416614978b2cd2e79ab11","spec_sha":"7efcebe7bd26ba0d5c93e7f159fc95ae23f3bbaff47ab2c0a47b735020210bf7","project_uri":"https://rubygems.org/gems/rspec-llama","gem_uri":"https://rubygems.org/gems/rspec-llama-0.1.0.gem","homepage_uri":null,"wiki_uri":null,"documentation_uri":"https://www.rubydoc.info/gems/rspec-llama/0.1.0","mailing_list_uri":null,"source_code_uri":null,"bug_tracker_uri":null,"changelog_uri":null,"funding_uri":null,"dependencies":{"development":[],"runtime":[{"name":"rspec","requirements":"~\u003e 3.0"}]}}